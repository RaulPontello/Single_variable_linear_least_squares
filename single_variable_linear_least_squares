import matplotlib.pyplot as plt

# 1) Input

x = [220, 220, 220, 220, 220, 225, 225, 225, 225, 225, 230, 230, 230, 230, 230, 235, 235, 235, 235, 235]
y = [137, 137, 137, 136, 135, 135, 133, 132, 133, 133, 128, 124, 126, 129, 126, 122, 122, 122, 119, 122]

# 2) Output

# 2.0) Lenght

n = len(x) 

# 2.1) Arithmetic Mean

x_mean = sum(x) / n
y_mean = sum(y) / n

# 2.2) Variability

Sxx = sum([(i - x_mean) ** 2 for i in x])  # sum of the squares of the difference between each xi and x_mean
Syy = sum([(i - y_mean) ** 2 for i in y])  # sum of the squares of the difference between each yi and y_mean
Sxy = sum([(i - x_mean) * (j - y_mean) for i, j in zip(x, y)])  # sum of the product of (xi - x_mean) * (yi - y_mean)

# 2.3) Variance

x_variance = Sxx / n
y_variance = Syy / n

# 2.4) Standard deviation

x_std = x_variance ** 0.5
y_std = y_variance ** 0.5

# 2.5) Covariance

Covariance = Sxy / n

# 2.6) Regression line (y = b0 + b1 * x + ϵ)

b1 = Sxy / Sxx
b0 = y_mean - b1 * x_mean
y_predicted = [b0 + b1 * i for i in x]

# 2.7) Sum of squares
# OBS: SST = SSR + SSE

sumsOfSquaresTotal = Syy # SST or TSS, measures the amount of variability inherent in the response before the regression is performed
sumsOfSquaresRegression = sum([(i - y_mean) ** 2 for i in y_predicted]) # SSR, measures the amount of variability in the response explained performing the regression
sumsOfSquaresError = sum([(i - j) ** 2 for i, j in zip(y, y_predicted)]) # SSE or RSS, measures the amount of variability in the response that is left unexplained after performing the regression
sumsOfAbsolutesError = sum([abs(i - j) for i, j in zip(y, y_predicted)]) # SSA
residualStandardError = (sumsOfSquaresError / (n - 2)) ** 0.5 # RSE, estimate of the standard deviation of ϵ

# 2.8) Assessing the Accuracy of the Model

meanSquaredError = sumsOfSquaresError / n # MSE
rootMeanSquaredError = meanSquaredError ** 0.5 # RMSE
meanAbsoluteError = sumsOfAbsolutesError / n # MAE
pearsonCoefficient = Covariance / (x_std * y_std)
R_squared = (sumsOfSquaresRegression) / Syy # R², proportion of variability in Y that can be explained using X
R_squared_adjusted = 1 - (1 - R_squared) * (n - 1) / (n - 2)

# 2.9) Assessing the Accuracy of the Coefficient Estimates

standardError_b0 = residualStandardError * ((1 / n) + ((x_mean ** 2) / Sxx)) # Variance of b0
standardError_b1 = residualStandardError / Sxx # Variance of b1
95_percent_confidenceInterval_b0 = [b0 - 2 * standardError_b0 ** 0.5, b0 + 2 * standardError_b0 ** 0.5]
95_percent_confidenceInterval_b1 = [b1 - 2 * standardError_b1 ** 0.5, b1 + 2 * standardError_b1 ** 0.5]
t_statistic_b0 = b0 / (standardError_b0 ** 0.5)
t_statistic_b1 = b1 / (standardError_b1 ** 0.5)

# 3) Plotting

plt.scatter(x, y)
fig = plt.plot(x, y_predicted, lw=4, c='orange', label='regression line')
plt.xlabel('x')
plt.ylabel('y')
plt.show()

# 4) Results

print('x_mean = ', x_mean)
print('x_variance = ', x_variance)
print('x_std = ', x_std)
print('y_mean = ', y_mean)
print('y_variance = ', y_variance)
print('y_std = ', y_std)
print('Sxx = ', Sxx)
print('Syy = ', Syy)
print('Sxy = ', Sxy)
print('Covariance = ', Covariance)
print('b0 = ', b0)
print('b1 = ', b1)
print('Sum of Squares Total = ', Syy)
print('Sum of Squares Regression = ', sumsOfSquaresRegression)
print('Sum of Squares Error = ', sumsOfSquaresError)
print('Sum of Absolutes Error = ', sumsOfAbsolutesError)
print('Residual Standard Error = ', residualStandardError)
print('Standard Error b0 = ', standardError_b0)
print('Standard Error b1 = ', standardError_b1)
print('95 % Confidence Interval for b0 = ', 95_percent_confidenceInterval_b0)
print('95 % Confidence Interval for b1 = ', 95_percent_confidenceInterval_b1)
print('Mean Squared Error = ', meanSquaredError1
print('Root Mean Squared Error = ', rootMeanSquaredError)
print('Mean Absolute Error = ', meanAbsoluteError)
print('Pearson correlation coefficient = ', pearsonCoefficient)
print('R_squared = ', R_squared)
print('R_squared_adjusted = ', R_squared_adjusted)
