import matplotlib.pyplot as plt
import numpy as np
import pandas as pd 

# Input

data = pd.read_csv('SAT.csv', sep = ',')
x = data['SAT']
y = data['GPA']

# Output

# Lenght

n = len(x) 

# Arithmetic Mean

x_mean = sum(x) / n
y_mean = sum(y) / n

# Variability

Sxx = sum([(i - x_mean) ** 2 for i in x])  # sum of the squares of the difference between each xi and x_mean
Syy = sum([(i - y_mean) ** 2 for i in y])  # sum of the squares of the difference between each yi and y_mean
Sxy = sum([(i - x_mean) * (j - y_mean) for i, j in zip(x, y)])  # sum of the product of (xi - x_mean) * (yi - y_mean)

# Variance

x_variance = Sxx / n
y_variance = Syy / n

# Standard deviation

x_std = x_variance ** 0.5
y_std = y_variance ** 0.5

# Covariance

covariance = Sxy / n

# Regression equation (y = b0 + b1 * x + ϵ)

b1 = Sxy / Sxx
b0 = y_mean - b1 * x_mean
y_predicted = [b0 + b1 * i for i in x]

# Sum of squares
# OBS: SST = SSR + SSE

sum_squares_total = Syy # SST or TSS, measures the amount of variability inherent in the response before the regression is performed
sum_squares_regression = sum([(i - y_mean) ** 2 for i in y_predicted]) # SSR, measures the amount of variability in the response explained performing the regression
sum_squares_error = sum([(i - j) ** 2 for i, j in zip(y, y_predicted)]) # SSE or RSS, measures the amount of variability in the response that is left unexplained after performing the regression
sum_absolutes_error = sum([abs(i - j) for i, j in zip(y, y_predicted)]) # SSA
error_variance = sum_squares_error / (n - 2)
error_standard_deviation = error_variance ** 0.5 # RSE (Residual Standard Error), estimate of the standard deviation of ϵ

# Assessing the Accuracy of the Model

mean_squared_error = sum_squares_error / n # MSE
root_mean_squared_error = mean_squared_error ** 0.5 # RMSE
mean_absolute_error = sum_absolutes_error / n # MAE
pearson_coefficient = covariance / (x_std * y_std)
R_squared = (sum_squares_regression) / sum_squares_total # R², proportion of variability in Y that can be explained using the linear model for X
R_squared_adjusted = 1 - (1 - R_squared) * (n - 1) / (n - 2)

# Assessing the Accuracy of the Coefficient Estimates
# The following functions will be used to determine p-value

def normal(x, mu, sigma):
    """
    Function used to determine the probability density of normal distribution
    :param x: Input
    :param mu: Mean of the distribution
    :param sigma: Standard deviation
    :return: Probability density of normal distribution
    """

    nominator = np.e**(- ((x - mu)**2) / (2 * sigma**2))
    denominator = (sigma * (2 * np.pi)**0.5)
    return nominator / denominator

def integrate_normal(a, b, n, mu, sigma):
    """
    Function used to determine the integral (area) of the probability density of normal distribution
    using the middle method in the interval [a, b]
    :param a: Start point of the interval [a, b]
    :param b: End point of interval [a, b]
    :param n: Number of divisions of interval [a, b]
    :param mu: Mean of the distribution
    :param sigma: Standard deviation of the distribution
    :return: Area between [a, b], output in decimals (0.4 not 40 %)
    """
    dx = float(b-a)/n
    area = 0
    midpoint = a + (dx/2)

    for i in range(n):
        area += normal(midpoint, mu, sigma) * dx
        midpoint += dx
    return area

variance_b0 = error_variance * ((1 / n) + ((x_mean ** 2) / Sxx)) # Variance of b0
standard_deviation_b0 = variance_b0 ** 0.5 # Standard Deviation of b0
variance_b1 = error_variance / Sxx # Variance of b1
standard_deviation_b1 = variance_b1 ** 0.5 # Standard Deviation of b1
percent_95_confidence_interval_b0 = [b0 - 2 * standard_deviation_b0, b0 + 2 * standard_deviation_b0]
percent_95_confidence_interval_b1 = [b1 - 2 * standard_deviation_b1, b1 + 2 * standard_deviation_b1]
t_statistic_b0 = b0 / standard_deviation_b0
t_statistic_b1 = b1 / standard_deviation_b1
F_statistic = sum_squares_regression / error_variance 
p_value_b0 = 2*(0.5 - integrate_normal(0, t_statistic_b0, 1000, 0, 1)) # Hypothesis testing: H0: b0 = 0, H1: b0 != 0 --> p small = reject H0 = b0 != 0 
p_value_b1 = 2*(0.5 - integrate_normal(0, t_statistic_b1, 1000, 0, 1)) # Hypothesis testing: H0: b1 = 0, H1: b1 != 0 --> p small = reject H0 = b1 != 0 

# Plotting

plt.scatter(x, y)
fig = plt.plot(x, y_predicted, lw=4, c='orange', label='regression line')
plt.xlabel('x')
plt.ylabel('y')
plt.show()

# Results

print('x_mean = ', x_mean)
print('x_variance = ', x_variance)
print('x_std = ', x_std)
print('y_mean = ', y_mean)
print('y_variance = ', y_variance)
print('y_std = ', y_std)
print('Sxx = ', Sxx)
print('Syy = ', Syy)
print('Sxy = ', Sxy)
print('Covariance = ', covariance)
print('b0 = ', b0)
print('b1 = ', b1)
print('Sum of Squares Total = ', Syy)
print('Sum of Squares Regression = ', sum_squares_regression)
print('Sum of Squares Error = ', sum_squares_error)
print('Sum of Absolutes Error = ', sum_absolutes_error)
print('Residual Standard Error = ', error_standard_deviation)
print('Standard Error b0 = ', standard_error_b0)
print('Standard Error b1 = ', standard_error_b1)
print('95 % Confidence Interval for b0 = ', percent_95_confidence_interval_b0)
print('95 % Confidence Interval for b1 = ', percent_95_confidence_interval_b1)
print('t-statistic for b0 = ', t_statistic_b0)
print('t-statistic for b1 = ', t_statistic_b1)
print('P-value for b0 = ', p_value_b0)
print('P-value for b1 = ', p_value_b1)
print('Mean Squared Error = ', mean_squared_error)
print('Root Mean Squared Error = ', root_mean_squared_error)
print('Mean Absolute Error = ', mean_absolute_error)
print('Pearson correlation coefficient = ', pearson_coefficient)
print('R_squared = ', R_squared)
print('R_squared_adjusted = ', R_squared_adjusted)
print('F_statistic = ', F_statistic)

